version: '3.7'

services:

  elasticsearch01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.2
    container_name: elasticsearch01
    environment:
      - node.name=elasticsearch01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elasticsearch02,elasticsearch03
      - cluster.initial_master_nodes=elasticsearch01,elasticsearch02,elasticsearch03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - type: volume
        source: data01
        target: /usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 15s
      timeout: 3s
      retries: 5

  elasticsearch02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.2
    container_name: elasticsearch02
    environment:
      - node.name=elasticsearch02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elasticsearch01,elasticsearch03
      - cluster.initial_master_nodes=elasticsearch01,elasticsearch02,elasticsearch03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - type: volume
        source: data02
        target: /usr/share/elasticsearch/data
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 15s
      timeout: 3s
      retries: 5

  elasticsearch03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.2
    container_name: elasticsearch03
    environment:
      - node.name=elasticsearch03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elasticsearch01,elasticsearch02
      - cluster.initial_master_nodes=elasticsearch01,elasticsearch02,elasticsearch03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - type: volume
        source: data03
        target: /usr/share/elasticsearch/data
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 15s
      timeout: 3s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:7.6.2
    container_name: kibana
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./elk/kibana-ha.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - 5601:5601
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "curl", "-f", "http://localhost:5601"]
      interval: 15s
      timeout: 3s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:7.6.2
    container_name: logstash
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    volumes:
      - ./elk/logstash-ha.yml:/usr/share/logstash/config/logstash.yml
      - ./elk/elasticsearch-template-ha.json:/usr/share/logstash/config/elasticsearch-template-ha.json
      - ./elk/pipeline-ha:/usr/share/logstash/pipeline:ro
    ports:
      - 9600:9600
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "curl", "-f", "http://localhost:9600"]
      interval: 15s
      timeout: 3s
      retries: 5

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ['CMD', '/bin/bash', '-c', 'echo "ruok" | nc -w 2 -q 2 localhost 2181 | grep imok']
      interval: 15s
      timeout: 3s
      retries: 5

  kafka:
    image: wurstmeister/kafka:2.12-2.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_PORT: 9095
      KAFKA_ADVERTISED_LISTENERS: LISTENER_KAFKA://kafka:9095
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_KAFKA:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_KAFKA
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIRS: /kafka/logs
      KAFKA_BROKER_ID: 1
      KAFKA_CREATE_TOPICS: "newsler-news-crawler:1:2, newsler-twitter-crawler:1:2"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./wait-for-it.sh:/usr/src/app/wait-for-it.sh
      - ./kafka/data/1:/kafka
      - ./kafka/kafka-healthcheck.sh:/bin/kafka-healthcheck.sh
    ports:
      - "9095:9092"
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD-SHELL", "/bin/kafka-healthcheck.sh"]
      interval: 30s
      timeout: 20s
      retries: 5

  kafka02:
    image: wurstmeister/kafka:2.12-2.5.0
    container_name: kafka02
    depends_on:
      - zookeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka02
      KAFKA_ADVERTISED_PORT: 9096
      KAFKA_ADVERTISED_LISTENERS: LISTENER_KAFKA://kafka:9096
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_KAFKA:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_KAFKA
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIRS: /kafka/logs
      KAFKA_BROKER_ID: 2
      KAFKA_CREATE_TOPICS: "newsler-news-crawler:1:2, newsler-twitter-crawler:1:2"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./wait-for-it.sh:/usr/src/app/wait-for-it.sh
      - ./kafka/data/1:/kafka
      - ./kafka/kafka-healthcheck.sh:/bin/kafka-healthcheck.sh
    ports:
      - "9096:9092"
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD-SHELL", "/bin/kafka-healthcheck.sh"]
      interval: 30s
      timeout: 20s
      retries: 5

  news-crawler:
    build:
      context: news-crawler
    image: news-crawler
    container_name: news-crawler
    environment:
      NEWS_INTERVAL_SECS: 60
      KAFKA_ENDPOINT: kafka:9095
      KAFKA_NEWS_TOPIC: newsler-news-crawler
      LOGGING_LEVEL: INFO
    volumes:
      - type: volume
        source: news-logs
        target: /usr/src/app/logs
      - ./wait-for-it.sh:/usr/src/app/wait-for-it.sh
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "/usr/local/bin/supervisorctl", "status", "all"]
      interval: 15s
      timeout: 5s
      retries: 5

  twitter-crawler:
    build:
      context: twitter-crawler
    image: twitter-crawler
    container_name: twitter-crawler
    env_file:
      - twitter-crawler/.env
    environment:
      KAFKA_ENDPOINT: "kafka:9095"
      KAFKA_TWITTER_TOPIC: "newsler-twitter-crawler"
    volumes:
      - type: volume
        source: twitter-logs
        target: /usr/src/app/logs
      - ./wait-for-it.sh:/usr/src/app/wait-for-it.sh
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "/usr/local/bin/supervisorctl", "status", "all"]
      interval: 15s
      timeout: 5s
      retries: 5

  connector:
    build:
      context: connector
    image: connector
    container_name: connector
    environment:
      CONSUMER_INTERVAL_SECS: 30
      ES_HOST: elasticsearch01
      ES_PORT: 9200
      KAFKA_ENDPOINT: kafka:9095
      KAFKA_NEWS_TOPIC: newsler-news-crawler
      KAFKA_TWITTER_TOPIC: newsler-twitter-crawler
    volumes:
      - type: volume
        source: connector-logs
        target: /usr/src/app/logs
      - ./wait-for-it.sh:/usr/src/app/wait-for-it.sh
    networks:
      - elk
    healthcheck:
      start_period: 30s
      test: ["CMD", "/usr/local/bin/supervisorctl", "status", "all"]
      interval: 15s
      timeout: 5s
      retries: 5

volumes:
  data01:
    driver: local
  data02:
    driver: local
  data03:
    driver: local
  news-logs:
    driver: local
  twitter-logs:
    driver: local
  connector-logs:
    driver: local

networks:
  elk:
    driver: bridge
