{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import enchant\n",
    "from string import punctuation \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lover_tweet = \"I love donald trump he is such a beautiful blond guy\"\n",
    "hater_tweet = \"I hate donald trump he is the worst man ever he is stupid\"\n",
    "h2 = \"I hate donald trump he is such an asshole he is the worst man ever I have never kwown someone worse than him he is stupid\"\n",
    "dirty_tweet = \"helloooooooo @person1 retweeted @person2: Corn has got to be the most delllllicious crop in the world!!!! #corn #thoughts...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegexReplacer(object):\n",
    "\n",
    "    replacement_patterns = [\n",
    "    (r'((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL'),\n",
    "    (r'@[^\\s]+', 'AT_USER'),\n",
    "    (r'#([^\\s]+)', r'\\1')\n",
    "    ]\n",
    "\n",
    "    def __init__(self, patterns=replacement_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s)\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "class RepeatReplacer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "        self.repl = r'\\1\\2\\3'\n",
    "\n",
    "    def replace(self, word):\n",
    "        if wordnet.synsets(word):\n",
    "            return word\n",
    "\n",
    "        repl_word = self.repeat_regexp.sub(self.repl, word)\n",
    "\n",
    "        if repl_word != word:\n",
    "            return self.replace(repl_word)\n",
    "        else:\n",
    "            return repl_word\n",
    "\n",
    "\n",
    "class SpellingReplacer(object):\n",
    "\n",
    "    def __init__(self, dict_name='en', max_dist=2):\n",
    "        self.spell_dict = enchant.Dict(dict_name)\n",
    "        self.max_dist = max_dist\n",
    "\n",
    "    def replace(self, word):\n",
    "        if self.spell_dict.check(word):\n",
    "            return word\n",
    "\n",
    "        suggestions = self.spell_dict.suggest(word)\n",
    "\n",
    "        if suggestions and edit_distance(word, suggestions[0]) <= self.max_dist:\n",
    "            return suggestions[0]\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "\n",
    "class TweetReplacer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER', 'URL'])\n",
    "\n",
    "    def _process_tweet(self, tweet):\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet)  # remove URLs\n",
    "        tweet = re.sub('@[^\\s]+', 'AT_USER', tweet)  # remove usernames\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)  # remove the # in #hashtag\n",
    "        tweet = word_tokenize(tweet)  # remove repeated characters (helloooooooo into hello)\n",
    "        print(tweet)\n",
    "        tweet = ' '.join(word for word in tweet if word not in self._stopwords)\n",
    "        print(tweet)\n",
    "        return tweet\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        analysis = TextBlob(self._process_tweet(tweet))\n",
    "        print(analysis.sentiment)\n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.675, subjectivity=0.8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = TweetSentimentAnalyzer()\n",
    "analyzer.get_tweet_sentiment(lover_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.45, subjectivity=0.7000000000000001)\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(get_tweet_sentiment(\"I love donald trump he is such a beautiful blond guy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.75, subjectivity=0.875)\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "analyzer.get_tweet_sentiment(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.6, subjectivity=0.8)\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "print(get_tweet_sentiment(\"I hate donald trump he is such an asshole he is the worst man ever I have never kwown someone worse than him he is stupid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloooooooo @person1 retweeted @person2: Corn has got to be the most delllllicious crop in the world!!!! #corn #thoughts...\n",
      "['helloooooooo', 'AT_USER', 'retweeted', 'AT_USER', 'corn', 'has', 'got', 'to', 'be', 'the', 'most', 'delllllicious', 'crop', 'in', 'the', 'world', '!', '!', '!', '!', 'corn', 'thoughts', '...']\n",
      "helloooooooo retweeted corn got delllllicious crop world corn thoughts ...\n",
      "helloooooooo retweeted corn got delllllicious crop world corn thoughts ...\n",
      "['helloooooooo', 'AT_USER', 'retweeted', 'AT_USER', 'corn', 'has', 'got', 'to', 'be', 'the', 'most', 'delllllicious', 'crop', 'in', 'the', 'world', '!', '!', '!', '!', 'corn', 'thoughts', '...']\n",
      "helloooooooo retweeted corn got delllllicious crop world corn thoughts ...\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = TweetSentimentAnalyzer()\n",
    "print(dirty_tweet)\n",
    "print(analyzer._process_tweet(dirty_tweet))\n",
    "analyzer.get_tweet_sentiment(dirty_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"Textblob is amazingly simple to use. What great fun!\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@person1 retweeted @person2: Corn has got to be the most delllllicious crop in the world!!!! #corn #thoughts...'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"retreated Worn has got to be the most delllllicious crop in the world corn thoughts\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(clean_tweet(dirty_text))\n",
    "b.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['retweeted',\n",
       "   'corn',\n",
       "   'got',\n",
       "   'delllllicious',\n",
       "   'crop',\n",
       "   'world',\n",
       "   'corn',\n",
       "   'thoughts',\n",
       "   '...'],\n",
       "  'Corn are delicious')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = {\"text\": dirty_text, \"label\": \"Corn are delicious\"}\n",
    "ppt = PreProcessTweets()\n",
    "ppt.process_tweets([tweet])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
